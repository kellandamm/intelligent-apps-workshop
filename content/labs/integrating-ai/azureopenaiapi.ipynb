{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Working with the Azure OpenAI API directly\n",
    "\n",
    "In this lab, we will perform a simple call to the Azure OpenAI API. This will prove that everything is setup correctly and working for the rest of the labs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, we need to retrieve values from the `.env` file which we will use to make calls to the Azure OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Azure OpenAI API Base Endpoint: https://ai-demos-aoai-kedamm.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "    \n",
    "API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n",
    "RESOURCE_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the API\n",
    "\n",
    "Now let's call the Azure OpenAI API with a prompt. To do this, we'll need the `id` of the Azure OpenAI deployment that contains our completion model. This should already be setup in the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a URL to call so that you can see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai-demos-aoai-kedamm.openai.azure.com//openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\n"
     ]
    }
   ],
   "source": [
    "url = RESOURCE_ENDPOINT + \"/openai/deployments/\" + DEPLOYMENT_ID + \"/chat/completions?api-version=\" + API_VERSION\n",
    "\n",
    "print(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see the full URL that we are going to call. This URL will use the specified deployment to call the **chat completions** API.\n",
    "\n",
    "Next, we will call the Azure OpenAI API using the URL above. We pass the API key in the HTTP header. We also send a JSON formatted body as part of the request which contains the *prompt* that we want to use to get a response from the OpenAI model. In this case, our prompt is \"Once upon a time\", which should cause the model to complete the prompt by generating a story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"protected_material_code\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"protected_material_text\": {\n",
      "          \"filtered\": false,\n",
      "          \"detected\": false\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"in a quiet village nestled between lush hills and a shimmering lake, there lived an old woman named Elara. She was known throughout the village for her mysterious garden, which bloomed with the most vibrant and unusual flowers anyone had ever seen. The flowers ranged in colors yet unseen and emitted fragrances that could enchant anyone who passed by.\\n\\nElara's secret to growing such a magical garden was closely guarded. Some villagers speculated she had made a pact with forest spirits, while others thought she might have come from a long line of powerful herbalists. Whatever the reason, Elara was beloved, not just for her mystical garden but for her wisdom and kindness.\\n\\nOne spring day, a young boy named Sam ventured into her garden, driven by a sense of wonder and curiosity that the stories of Elara\\u2019s garden had sparked in him. He found Elara tending to her flowers with great care, humming a gentle tune that seemed to weave around the plants like a soft breeze.\\n\\n\\u201cHello, Elara,\\u201d Sam said, slightly hesitating. \\u201cYour garden is more beautiful than I ever imagined. How do you make it so magical?\\u201d\\n\\nElara smiled warmly at Sam and paused from her work. \\u201cIt\\u2019s not about magic, dear Sam, but about understanding and listening,\\u201d she replied. She pointed to a plant with petals that shimmered like the finest silk. \\u201cEach plant has its own story, its own needs. If you take the time to listen and care for them truly, they will reward you with their beauty.\\u201d\\n\\nSam was entranced, not just by her words but by the soothing calmness with which she spoke. As the days passed, he returned to Elara\\u2019s garden again and again, eager to learn more. Elara taught him about each plant's unique characteristics, the way they interacted with the soil, the sun, and even how they responded to the touch of the wind.\\n\\nUnder Elara\\u2019s guidance, Sam slowly began to understand the delicate balance of nature. He learned how to nurture the plants, how to respect the surrounding ecosystem, and how every aspect of the garden was interconnected. Sam\\u2019s knack for gardening grew, and he soon managed to cultivate a small patch of flowers in his own backyard, drawing inspiration from Elara\\u2019s teachings.\\n\\nAs time went by, Elara grew weaker, and eventually, she passed away quietly, leaving behind her cherished garden as her legacy. The village mourned her passing but celebrated her life by tending to the garden she had loved so much.\\n\\nInspired by Elara\\u2019s wisdom and kindness, Sam made it his mission to share what he had learned with others. He transformed the garden into a place of learning and connection for villagers and travelers alike, continuing to inspire awe as it had done when Elara was alive. In this way, Elara\\u2019s garden thrived, not just through the vibrant blooms that flourished each season, but through the community that came together, united by a shared appreciation for the wonders of the natural world.\\n\\nAnd so, the village remembered Elara, not only for her remarkable garden but for the way she had taught them to see the magic all around them.\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1730759728,\n",
      "  \"id\": \"chatcmpl-APzxQ8QW7EGgZsfNpeyzi4qCPc1Vt\",\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ],\n",
      "  \"system_fingerprint\": \"fp_d54531d9eb\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 631,\n",
      "    \"prompt_tokens\": 12,\n",
      "    \"total_tokens\": 643\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(url, headers={\"api-key\": API_KEY}, json={\"messages\":[{\"role\": \"assistant\", \"content\": \"Once upon a time \"}]})\n",
    "\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the API call will be JSON data similar to the below example. Note that the response has been edited to make it easier to read.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"id\": \"chatcmpl-7wVxE2LNxaY6ZoxcWAmhiyrqaLZgf\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1694180212,\n",
    "  \"model\": \"gpt-35-turbo\",\n",
    "  \"prompt_filter_results\": [\n",
    "    {\n",
    "      \"prompt_index\": 0,\n",
    "      (content filter results removed for brevity)\n",
    "    }\n",
    "  ],\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"index\": 0,\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \", there was a magical kingdom called Tildor ... )))\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 366,\n",
    "    \"prompt_tokens\": 13,\n",
    "    \"total_tokens\": 379\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Here's some information about some of the more interesting pieces of data contained in that response.\n",
    "\n",
    "Key | Description\n",
    "--- | ---\n",
    "`model` | The model that was used to generate the response to the prompt\n",
    "`content` | This is the response that was generated by the OpenAI model. Note that the response example above was edited to remove most of the output to make it easier to read\n",
    "`finish_reason` | This is the reason that the model stopped generating the response. In this case, `stop` indicates the model determined it had fully completed the response without hitting any limits\n",
    "`completion_tokens` | The number of tokens that were used in generating the response\n",
    "`prompt_tokens` | The number of tokens that were consumed by the prompt\n",
    "`total_tokens` | The total number of tokens that were consumed by the request (`prompt_tokens` + `completion_tokens`)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we used the Azure OpenAI API directly to send a prompt to an OpenAI model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "In the next lab, we will look at using the OpenAI SDK to work with the Azure OpenAI service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Section\n",
    "\n",
    "ðŸ“£ [OpenAI Packages/Libraries](../02-OpenAIPackages/openai.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
